from abc import ABC, abstractmethod
from collections import defaultdict
from typing import Any, Dict, List
from warnings import warn

import numpy as np
import torch
import torch.nn as nn
from omegaconf import DictConfig
from torch import Tensor


class BasePredictor(nn.Module, ABC):
    def __init__(self, config: DictConfig) -> None:
        """
        Base API used for prediction in the interactive pipelines.

        Args:
            config (DictConfig): Configuration for each model in the
                OmegaConf format. All model parameters should be inside
                the config dictionary.
        """
        super(BasePredictor, self).__init__()
        self._config = config
        self._current_id: int = None

    @abstractmethod
    def _setup_model(self) -> None:
        """This function should be overloaded to setup the model"""
        self.model: nn.Module = None
        raise NotImplementedError

    @abstractmethod
    def prepare_prompts(self, prompts: List[Any]) -> List[Any]:
        """
        Prepare the prompts returned by the Sampler.
        For reference see the BaseSampler class.

        Args:
            prompts (List[Any]): List of prompts to be parser.

        Returns:
            Preprocessed list of prompts in the format needed by the model.
        """
        raise NotImplementedError

    def preprocess(self, inpts: Tensor) -> Tensor:
        return inpts

    def postprocess(self, inpts: Tensor) -> Tensor:
        return inpts

    @abstractmethod
    def predict(
        self, inpts: Tensor, prompts: List[Any], aux: Dict[str, Any], id: int
    ) -> Tensor:
        """
        Main prediction function, usually used with no gradient.

        Args:
            inputs (Tensor): Input tensor image (1, N, H, W).
                Currently only a batch of one is supported for
                interactive predictions.
            prompts (List[Any]): Raw prompts generated by a sampler.
            aux (Dict[Any]): Auxiliary inputs the model may need for
                prediction.
            id (int): id of the image being predicted on. If this changes
                some models may need to reset the prompt history and preprocess the new
                inputs.
        """
        assert id is not None, "id should not be None."
        raise NotImplementedError


class SamPredictor(BasePredictor):
    def __init__(self, config: DictConfig) -> None:
        super().__init__(config)

    def _setup_model(self) -> None:
        from segment_anything import SamPredictor as SP
        from segment_anything import sam_model_registry

        self.__sam_checkpoint = self._config.checkpoint
        self.__model_type = self._config.type
        sam = sam_model_registry[self.__model_type](self.__sam_checkpoint)
        self.model = SP(sam)

    def prepare_prompts(self, prompts: List[Any]) -> List[Any]:
        """
        Prepare the prompts returned by the Sampler.
        For reference see the BaseSampler class.

        Args:
            prompts (List[Any]): List of prompts to be parser.

        Returns:
            Preprocessed list of prompts in the format needed by the model.
        """
        sam_prompts = defaultdict(list)
        for prompt in prompts:
            if prompt["type"] == "point":
                sam_prompts["point_coords"].append(prompt["coords"])
                sam_prompts["point_labels"].append(prompt["label"])
            elif prompt["type"] == "bbox":
                sam_prompts["bbox"].append(prompt["coords"])
            else:
                warn(f"Ignoring invalid prompt type: {prompt['type']}.")

        for prompt, val in sam_prompts.items():
            sam_prompts[prompt] = np.array(val)
        return sam_prompts

    def predict(
        self, inpts: Tensor, prompts: List[Any], aux: Dict[str, Any], id: int
    ) -> Tensor:
        """
        Main prediction function, usually used with no gradient.

        Args:
            inputs (Tensor): Input tensor image (1, N, H, W).
                Currently only a batch of one is supported for
                interactive predictions.
            prompts (List[Any]): Raw prompts generated by a sampler.
            aux (Dict[Any]): Auxiliary inputs the model may need for
                prediction.
            id (int): id of the image being predicted on. If this changes
                some models may need to reset the prompt history and preprocess the new
                inputs.
        """
        assert id is not None, "id should not be None."
        if id != self._current_id:
            self.model.set_image(inpts)
            self._current_id = id

        prompts = self.prepare_prompts(prompts)
        masks, scores, logits = self.model.predict(
            **prompts, mask_input=aux, multimask_output=False
        )

        # self.logger.log_metric("sam_pred_iou", scores[0])
        # Logic for returning the best mask
        self._prev_mask = logits
        return masks[0], logits


class RITMPredictor(BasePredictor):
    def __init__(self, config: DictConfig) -> None:
        super().__init__(config)
        # Fix for numpy.int being deprecated since numpy 1.20
        np.int = np.int_
        from .isegm.inference.clicker import Click, Clicker

        self._clicker = Clicker
        self._click = Click
        self._threshold = self._config.threshold

    def _setup_model(self) -> None:
        from .isegm.inference import utils
        from .isegm.inference.predictors import get_predictor

        model = utils.load_is_model(self._config.checkpoint)
        self.model = get_predictor(model, "NoBRS", "cpu", prob_thresh=self._threshold)

    def prepare_prompts(self, prompts: List[Any]) -> List[Any]:
        """
        Prepare the prompts returned by the Sampler.
        For reference see the BaseSampler class.

        Args:
            prompts (List[Any]): List of prompts to be parser.

        Returns:
            Preprocessed list of prompts in the format needed by the model.
        """
        clicker = self._clicker(gt_mask=None, init_clicks=None)
        for prompt in prompts:
            if prompt["type"] == "point":
                points = self._click(
                    is_positive=prompt["label"],
                    coords=prompt["coords"][::-1],  # coords are in (y, x) format
                )
                clicker.add_click(points)
            else:
                warn(f"Ignoring invalid prompt type: {prompt['type']}.")
        return clicker

    def predict(
        self, inpts: Tensor, prompts: List[Any], aux: Dict[str, Any], id: int
    ) -> Tensor:
        """
        Main prediction function.

        Args:
            inputs (Tensor): Input tensor image (1, N, H, W).
                Currently only a batch of one is supported for
                interactive predictions.
            prompts (List[Any]): Raw prompts generated by a sampler.
            aux (Dict[Any]): Auxiliary inputs the model may need for
                prediction.
            id (int): id of the image being predicted on. If this changes
                some models may need to reset the prompt history and preprocess the new
                inputs.
        """
        assert id is not None, "id should not be None."

        h, w, c = inpts.shape
        if id != self._current_id:
            self.model.set_input_image(inpts)
            self._current_id = id

        if aux is not None:
            aux = Tensor(aux).unsqueeze(0).unsqueeze(0)
        else:
            aux = torch.zeros((1, 1, h, w))

        prompts = self.prepare_prompts(prompts)
        # By default RITM will use the previous prediction saved internally.
        logits = self.model.get_prediction(prompts, aux)
        return logits > self._threshold, logits
